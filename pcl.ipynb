{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pcl import train, models\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Sequence, Tuple\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import pil_to_tensor, resize, hflip\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def random_roll(image: torch.Tensor) -> torch.Tensor:\n",
    "    image = torch.roll(image, int(random.random() * image.size(-1)), dims=-1)\n",
    "    return image\n",
    "\n",
    "def habitat_transforms(image: torch.Tensor) -> torch.Tensor:\n",
    "    image = random_roll(image)\n",
    "    if random.random() > 0.5:\n",
    "        image = hflip(image)\n",
    "    return image\n",
    "\n",
    "class Habitat(Dataset):\n",
    "    def __init__(self, data_dir: str, use_transform: bool = False, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.use_transform = use_transform\n",
    "        self._meta_path = None\n",
    "        self._size = None\n",
    "        self._paths = None\n",
    "        self._headings = None\n",
    "        self._timestamps = None\n",
    "        self._coordinates = None\n",
    "        \n",
    "    def transform(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return habitat_transforms(x)\n",
    "\n",
    "    @property\n",
    "    def meta_path(self) ->str:\n",
    "        if self._meta_path is None:\n",
    "            path = Path(self.data_dir)\n",
    "            path = path / f'{path.stem}.json'\n",
    "            self._meta_path = path.absolute().resolve().as_posix()\n",
    "        return self._meta_path\n",
    "\n",
    "    @property\n",
    "    def paths(self) -> Sequence[Path]:\n",
    "        if self._paths is None:\n",
    "            self._paths = list(Path(self.data_dir).glob(\"*.png\"))\n",
    "            self._paths = sorted(self._paths, key=lambda x: int(x.stem.split(\"_\")[1]))\n",
    "        return self._paths\n",
    "\n",
    "    @property\n",
    "    def coordinates(self):\n",
    "        if self._coordinates is None:\n",
    "            with open(self.meta_path, \"r\") as file:\n",
    "                coordinates = json.load(file)[\"pose_list\"]\n",
    "            coordinates = torch.from_numpy(np.array(coordinates)).double()\n",
    "            coordinates = coordinates[:, [0, 2]]\n",
    "            self._coordinates = coordinates\n",
    "        return self._coordinates\n",
    "\n",
    "    @property\n",
    "    def headings(self):\n",
    "        if self._headings is None:\n",
    "            with open(self.meta_path, \"r\") as file:\n",
    "                headings = json.load(file)[\"pose_list\"]\n",
    "            self._headings = torch.as_tensor(headings, dtype=torch.float64)[:, 3:]\n",
    "        return self._headings\n",
    "\n",
    "    @property\n",
    "    def timestamps(self) -> torch.Tensor:\n",
    "        if self._timestamps is None:\n",
    "            timestamps = range(len(self))\n",
    "            self._timestamps = torch.tensor(timestamps)\n",
    "        return self._timestamps\n",
    "\n",
    "    def load(self, idx: int) -> Image:\n",
    "        return resize(pil_to_tensor(Image.open(str(self.paths[idx])).convert(\"RGB\")), (64, 256))\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, ...]:\n",
    "        tensor = self.load(idx)\n",
    "        if self.use_transform:\n",
    "            tensor = self.transform(tensor)\n",
    "        return tensor\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self._size is None:\n",
    "            self._size = len(self.paths)\n",
    "        return self._size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Habitat(\"data/Crandon\", use_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabe1c4889134195a99d1eb081e8be7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.build(\"resnet18\", pretrained=True, feature_size=512)\n",
    "model = train.start(\n",
    "    model,\n",
    "    dataset,\n",
    "    \"cuda\",\n",
    "    batch_size=32,\n",
    "    total_epochs=100,\n",
    "    num_workers=4,\n",
    "    num_cluster_iters=5,\n",
    "    num_kmeans_iters=10,\n",
    "    temporature=0.1,\n",
    "    concentration=0.1,\n",
    "    momentum=0.95,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31d23320fb02b4df4e2df51e36851867ddef600d7ff673f6f449b0dd5776f941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
